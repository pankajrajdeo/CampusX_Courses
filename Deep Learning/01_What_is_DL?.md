# üìò Lecture Notes: Introduction to Deep Learning

## 1. Introduction

* The lecture introduces **Deep Learning (DL)** as part of a development course.
* Goals:

  * Understand **what Deep Learning is**.
  * Learn the **difference between Machine Learning (ML) and Deep Learning**.
  * Explore **why Deep Learning became so popular** in recent years.
  * Build a **foundation for future deep learning concepts and applications**.

---

## 2. Definitions of Deep Learning

### 2.1 Simple Definition

* Deep Learning is a **sub-field of Artificial Intelligence (AI)** and **Machine Learning**.
* Inspired by the **structure and functioning of the human brain**.
* Uses a **logical structure called Neural Networks** to process information.

**Breakdown:**

* **AI**: Umbrella field; goal is to create intelligent machines.
* **Machine Learning (ML)**: Sub-field of AI ‚Üí learns patterns from data.
* **Deep Learning (DL)**: Sub-field of ML ‚Üí uses **neural networks** inspired by the brain.

---

### 2.2 Technical Definition

* Deep Learning is part of a **broader family of ML methods** based on **artificial neural networks with representation learning**.
* Algorithms use **multiple layers** to extract **progressively higher-level features** from raw data.

**Key takeaway:**
Deep Learning ‚âà Machine Learning + Neural Networks + Automatic Feature Extraction (Representation Learning).

---

## 3. Neural Networks Basics

### 3.1 Structure

* **Unit (Neuron/Perceptron):** Smallest element; performs simple calculations.
* **Weights:** Connections between neurons; determine importance of signals.
* **Layers:**

  * **Input Layer:** Accepts raw data.
  * **Hidden Layers:** Perform feature extraction.
  * **Output Layer:** Produces predictions.

> Deep Learning gets its name because it uses **many hidden layers**.

---

### 3.2 Types of Neural Networks

* **Feedforward Neural Network (FNN):** Simplest; data flows forward only.
* **Convolutional Neural Network (CNN):** Specially good for images.
* **Recurrent Neural Network (RNN):** Works well for sequential data (e.g., text, speech).
* **Generative Adversarial Networks (GANs):** Generate new data (e.g., images, text).

---

### 3.3 Example: Simple Neural Network in Code

```python
import tensorflow as tf
from tensorflow.keras import layers, models

# Simple feedforward network for binary classification
model = models.Sequential([
    layers.Dense(16, activation='relu', input_shape=(20,)),  # 20 input features
    layers.Dense(8, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # binary output
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

print(model.summary())
```

---

## 4. Representation Learning

### 4.1 Traditional ML vs Deep Learning

* In **Machine Learning**:

  * Humans **manually design features** (feature engineering).
  * Example: For dog vs cat images ‚Üí engineer features like size, color, texture.
* In **Deep Learning**:

  * Model **automatically extracts features** layer by layer.
  * Lower layers ‚Üí simple features (edges, textures).
  * Higher layers ‚Üí complex features (shapes, objects).

---

### 4.2 Example: Dog vs Cat Classifier

* **ML approach**: Extract size, fur color, ear shape ‚Üí train classifier.
* **DL approach**: Feed raw pixels ‚Üí neural network automatically learns patterns.

---

## 5. Differences: Machine Learning vs Deep Learning

| Aspect                | Machine Learning (ML)         | Deep Learning (DL)                         |
| --------------------- | ----------------------------- | ------------------------------------------ |
| **Data Requirement**  | Works with small datasets     | Requires very large datasets               |
| **Hardware**          | Runs on CPU                   | Needs GPU/TPU for training                 |
| **Training Time**     | Fast                          | Slow (can take days/weeks)                 |
| **Prediction Time**   | Sometimes slower              | Usually very fast                          |
| **Feature Selection** | Manual (needs domain experts) | Automatic (representation learning)        |
| **Interpretability**  | High (transparent models)     | Low (black-box, hard to explain decisions) |

---

### Example Graph: Performance vs Data

* With **small data** ‚Üí ML performs better.
* With **large data** ‚Üí DL scales better and outperforms ML.

---

## 6. Why is Deep Learning so Popular?

### 6.1 Key Reasons

1. **Data Availability (Big Data)**

   * Explosion of smartphones, internet, and social media.
   * Large public datasets available (e.g., ImageNet, COCO, YouTube-8M).

2. **Hardware Improvements**

   * GPUs ‚Üí parallel processing for faster training.
   * Specialized chips:

     * **TPU (Tensor Processing Unit)** by Google.
     * **NPU (Neural Processing Unit)** in smartphones.
     * **FPGA & ASICs** for custom workloads.

3. **Frameworks & Libraries**

   * **TensorFlow + Keras** (Google): Industry adoption.
   * **PyTorch** (Facebook): Preferred for research.
   * AutoML tools for no-code model building.

4. **Architectures**

   * Pre-trained models & transfer learning.
   * Examples:

     * CNNs (ResNet, VGG) for vision.
     * RNNs, Transformers (BERT, GPT) for text.
     * GANs for generation.

5. **Community Support**

   * Researchers, developers, teachers, students contributing.
   * Open-source sharing accelerates progress.

---

### 6.2 Example: Transfer Learning with Pre-trained Model

```python
from tensorflow.keras.applications import ResNet50

# Load pretrained ResNet50
base_model = ResNet50(weights="imagenet", include_top=False, input_shape=(224,224,3))

# Freeze base model layers
base_model.trainable = False

# Add custom classifier
model = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(2, activation='softmax')  # e.g. Dog vs Cat
])
```

---

## 7. Challenges in Deep Learning

* **High data requirement**.
* **High computational cost**.
* **Low interpretability** (black box issue).
* **Overfitting risk** with limited data.

---

## 8. Analogy

* ML = ü™° Needle ‚Üí precise, efficient for small tasks.
* DL = ‚öîÔ∏è Sword ‚Üí powerful, best for large and complex tasks.
* Choose depending on **problem size, data availability, and explainability needs**.

---

## 9. Recap

1. Deep Learning = sub-field of ML using neural networks.
2. Neural networks inspired by brain; layers learn progressively complex features.
3. Key difference from ML: **automatic feature extraction**.
4. DL needs **large data + powerful hardware**.
5. Became popular due to **data availability, GPUs, frameworks, architectures, community**.
6. Both ML and DL have their place ‚Üí use wisely.
